# -*- coding: utf-8 -*-
"""Welcome to Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

seconds_in_a_week = 7 * seconds_in_a_day
seconds_in_a_week

"""Colab notebooks allow you to combine <strong>executable code</strong> and <strong>rich text</strong> in a single document, along with <strong>images</strong>, <strong>HTML</strong>, <strong>LaTeX</strong> and more. When you create your own Colab notebooks, they are stored in your Google Drive account. You can easily share your Colab notebooks with co-workers or friends, allowing them to comment on your notebooks or even edit them. To find out more, see <a href="/notebooks/basic_features_overview.ipynb">Overview of Colab</a>. To create a new Colab notebook you can use the File menu above, or use the following link: <a href="http://colab.research.google.com#create=true">Create a new Colab notebook</a>.

Colab notebooks are Jupyter notebooks that are hosted by Colab. To find out more about the Jupyter project, see <a href="https://www.jupyter.org">jupyter.org</a>.

<div class="markdown-google-sans">

## Data science
</div>

With Colab you can harness the full power of popular Python libraries to analyse and visualise data. The code cell below uses <strong>numpy</strong> to generate some random data, and uses <strong>matplotlib</strong> to visualise it. To edit the code, just click the cell and start editing.

You can import your own data into Colab notebooks from your Google Drive account, including from spreadsheets, as well as from GitHub and many other sources. To find out more about importing data, and how Colab can be used for data science, see the links below under <a href="#working-with-data">Working with data</a>.
"""

import numpy as np
import IPython.display as display
from matplotlib import pyplot as plt
import io
import base64

ys = 200 + np.random.randn(100)
x = [x for x in range(len(ys))]

fig = plt.figure(figsize=(4, 3), facecolor='w')
plt.plot(x, ys, '-')
plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)
plt.title("Sample Visualization", fontsize=10)

data = io.BytesIO()
plt.savefig(data)
image = F"data:image/png;base64,{base64.b64encode(data.getvalue()).decode()}"
alt = "Sample Visualization"
display.display(display.Markdown(F"""![{alt}]({image})"""))
plt.close(fig)

"""Colab notebooks execute code on Google's cloud servers, meaning that you can leverage the power of Google hardware, including <a href="#using-accelerated-hardware">GPUs and TPUs</a>, regardless of the power of your machine. All you need is a browser.

For example, if you find yourself waiting for <strong>pandas</strong> code to finish running and want to go faster, you can switch to a GPU runtime and use libraries like <a href="https://rapids.ai/cudf-pandas">RAPIDS cuDF</a> that provide zero-code-change acceleration.

To learn more about accelerating pandas on Colab, see the <a href="https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_colab_demo.ipynb">10-minute guide</a> or
 <a href="https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_stocks_demo.ipynb">US stock market data analysis demo</a>.

<div class="markdown-google-sans">

## Machine learning
</div>

With Colab you can import an image dataset, train an image classifier on it and evaluate the model, all in just <a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb">a few lines of code</a>.

Colab is used extensively in the machine learning community with applications including:
- Getting started with TensorFlow
- Developing and training neural networks
- Experimenting with TPUs
- Disseminating AI research
- Creating tutorials

To see sample Colab notebooks that demonstrate machine learning applications, see the <a href="#machine-learning-examples">machine learning examples</a> below.

<div class="markdown-google-sans">

## More resources

### Working with notebooks in Colab

</div>

- [Overview of Colab](/notebooks/basic_features_overview.ipynb)
- [Guide to markdown](/notebooks/markdown_guide.ipynb)
- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)
- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)
- [Interactive forms](/notebooks/forms.ipynb)
- [Interactive widgets](/notebooks/widgets.ipynb)

<div class="markdown-google-sans">

<a name="working-with-data"></a>
### Working with data
</div>

- [Loading data: Drive, Sheets and Google Cloud Storage](/notebooks/io.ipynb)
- [Charts: visualising data](/notebooks/charts.ipynb)
- [Getting started with BigQuery](/notebooks/bigquery.ipynb)

<div class="markdown-google-sans">

### Machine learning

<div>

These are a few of the notebooks related to machine learning, including Google's online machine learning course. See the <a href="https://developers.google.com/machine-learning/crash-course/">full course website</a> for more.
- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)
- [Intro to RAPIDS cuDF to accelerate pandas](https://nvda.ws/rapids-cudf)
- [Getting started with cuML's accelerator mode](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cuml_sklearn_colab_demo.ipynb)
- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)

<div class="markdown-google-sans">

<a name="using-accelerated-hardware"></a>
### Using accelerated hardware
</div>

- [TensorFlow with GPUs](/notebooks/gpu.ipynb)
- [TPUs in Colab](/notebooks/tpu.ipynb)

<div class="markdown-google-sans">

<a name="machine-learning-examples"></a>

### Featured examples

</div>

- <a href="https://tensorflow.org/hub/tutorials/tf2_image_retraining">Retraining an Image Classifier</a>: Build a Keras model on top of a pre-trained image classifier to distinguish flowers.
- <a href="https://tensorflow.org/hub/tutorials/tf2_text_classification">Text Classification</a>: Classify IMDB film reviews as either <em>positive</em> or <em>negative</em>.
- <a href="https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization">Style Transfer</a>: Use deep learning to transfer style between images.
- <a href="https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa">Multilingual Universal Sentence Encoder Q&amp;A</a>: Use a machine-learning model to answer questions from the SQuAD dataset.
- <a href="https://tensorflow.org/hub/tutorials/tweening_conv3d">Video Interpolation</a>: Predict what happened in a video between the first and the last frame.
"""

# ==============================================================
# üß† Very Low Accuracy Fake News Model (~50%)
# TF-IDF + Naive Bayes (intentionally weakened)
# ==============================================================

!pip install pandas scikit-learn --quiet

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# ==============================================================
# 1Ô∏è‚É£ Load Data
# ==============================================================

true_df = pd.read_csv("/content/True.csv", on_bad_lines='skip', engine='python')
fake_df = pd.read_csv("/content/Fake (1).csv", on_bad_lines='skip', engine='python')

true_df["label"] = 1
fake_df["label"] = 0

# Combine + weaken model intentionally
df = pd.concat([true_df, fake_df], axis=0).sample(frac=0.1, random_state=42)
df["text"] = df["title"].astype(str) + " " + df["text"].astype(str)

# Randomly flip 30% of labels
flip_idx = np.random.choice(df.index, size=int(0.3 * len(df)), replace=False)
df.loc[flip_idx, "label"] = 1 - df.loc[flip_idx, "label"]

print("‚úÖ Data prepared:", df.shape)

# ==============================================================
# 2Ô∏è‚É£ Train‚ÄìTest Split
# ==============================================================

X_train, X_test, y_train, y_test = train_test_split(
    df["text"], df["label"], test_size=0.3, random_state=42
)

# ==============================================================
# 3Ô∏è‚É£ TF-IDF Vectorization (very few features)
# ==============================================================

vectorizer = TfidfVectorizer(stop_words="english", max_features=200)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# ==============================================================
# 4Ô∏è‚É£ Train Naive Bayes Model
# ==============================================================

model = MultinomialNB(alpha=5.0)
model.fit(X_train_tfidf, y_train)

# ==============================================================
# 5Ô∏è‚É£ Evaluate
# ==============================================================

y_pred = model.predict(X_test_tfidf)
acc = accuracy_score(y_test, y_pred)

print(f"\nüéØ Model Accuracy: {acc*100:.2f}%")
print("\nüìä Classification Report:")
print(classification_report(y_test, y_pred, target_names=["Fake", "True"]))

# ==============================================================
# 6Ô∏è‚É£ Sample Predictions (Dataset-based + custom)
# ==============================================================

samples = [
    # TRUE samples from dataset style
    "U.S. military says it successfully tests missile defense system.",
    "Google announces new AI system to improve search accuracy.",
    "Scientists discover new species of dinosaur in Argentina.",
    "Economy shows strongest quarterly growth in two years, report says.",
    "Medical researchers develop promising treatment for Alzheimer‚Äôs disease.",

    # FAKE samples
    "Donald Trump caught hiring aliens from Mars, leaked documents reveal.",
    "Scientists say chocolate cures all diseases in groundbreaking study.",
    "Man travels through time and returns with proof of the future.",
    "NASA admits the Earth is flat in deleted report.",
    "Queen of England spotted shapeshifting into reptilian form.",

    # More dataset-like headlines
    "Russia agrees to resume peace talks after international pressure.",
    "Man claims he saw a dragon flying over the Himalayas.",
    "New study shows drinking lemon water extends life by 20 years.",
    "Researchers find microplastics in snowfall on Mount Everest.",
    "Government secretly building underground alien communication base."
]

sample_tfidf = vectorizer.transform(samples)
preds = model.predict(sample_tfidf)

print("\n================ SAMPLE PREDICTIONS ================\n")
for text, pred in zip(samples, preds):
    label = "True" if pred == 1 else "Fake"
    print(f"üì∞ '{text}' ‚Üí Predicted as: {label}")